apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-conf
  namespace: au05-sales-test
data:
  workflow: "1"  # Only allow 1 workflow to run at a time
  spark-defaults.conf: |
    spark.kubernetes.container.image=eragani/spark:3.3.1

---
apiVersion: v1
kind: Secret
metadata:
  name: docker-secret
  namespace: au05-sales-test
data:
  .dockerconfigjson: eyJhdXRocyI6eyJkb2NrZXIuaW8iOnsidXNlcm5hbWUiOiJlcmFnYW5pIiwicGFzc3dvcmQiOiJBbnVyYWRoYUAxMjM0IyQiLCJlbWFpbCI6ImVyYWdhbmlAZ21haWwuY29tIiwiYXV0aCI6IlpYSmhaMkZ1YVRwQmJuVnlZV1JvWVVBeE1qTTBJeVE9In19fQ==
type: kubernetes.io/dockerconfigjson
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: spark
  namespace: au05-sales-test
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: au05-sales-test
  name: spark-role
rules:
- apiGroups: [""]
  resources: ["*"]
  verbs: ["*"]
- apiGroups: ["sparkoperator.k8s.io"]  # This is for the Spark operator resources
  resources: ["sparkapplications", "scheduledsparkapplications"]
  verbs: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: spark-rolebinding
  namespace: au05-sales-test
subjects:
- kind: ServiceAccount
  name: spark
  namespace: au05-sales-test
roleRef:
  kind: Role
  name: spark-role
  apiGroup: rbac.authorization.k8s.io

---
# apiVersion: sparkoperator.k8s.io/v1beta2
# kind: ScheduledSparkApplication
# metadata:
#   name: user-cdc-event-proc-1
#   namespace: au05-sales-test
# spec:
#   schedule: "*/2 * * * *"
#   concurrencyPolicy: Forbid
#   template:
#     type: Scala
#     mode: cluster
#     image: "eragani/spark:3.3.1"
#     mainClass: "step1.UserCDCEventProcessor"
#     mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#     sparkVersion: "3.3.1"
#     restartPolicy:
#       type: Never
#     driver:
#       cores: 1
#       coreLimit: "1200m"
#       memory: "512m"
#       labels:
#         version: 3.3.1
#       serviceAccount: spark
#     executor:
#       cores: 1
#       instances: 2
#       memory: "512m"
#       labels:
#         version: 3.3.1
#       #serviceAccount: spark
#     sparkConf:
#       "spark.kubernetes.namespace": "au05-sales-test"
#       "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#       "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#       "spark.kubernetes.driver.container.image": "eragani/spark:3.3.1"
#       "spark.kubernetes.executor.container.image": "eragani/spark:3.3.1"
#       "spark.eventLog.enabled": "false"
#       "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#     arguments:
#       - "au05_sales_test"

---
# apiVersion: sparkoperator.k8s.io/v1beta2
# kind: ScheduledSparkApplication
# metadata:
#   name: user-cdc-event-proc-2
#   namespace: au05-sales-test
# spec:
#   schedule: "*/4 * * * *"
#   concurrencyPolicy: Forbid
#   template:
#     type: Scala
#     mode: cluster
#     image: "eragani/spark:3.3.1"
#     mainClass: "step1.UserCDCEventProcessor"
#     mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#     sparkVersion: "3.3.1"
#     restartPolicy:
#       type: Never
#     driver:
#       cores: 1
#       coreLimit: "1200m"
#       memory: "512m"
#       labels:
#         version: 3.3.1
#       serviceAccount: spark
#     executor:
#       cores: 1
#       instances: 2
#       memory: "512m"
#       labels:
#         version: 3.3.1
#       #serviceAccount: spark
#     sparkConf:
#       "spark.kubernetes.namespace": "au05-sales-test"
#       "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#       "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#       "spark.kubernetes.driver.container.image": "eragani/spark:3.3.1"
#       "spark.kubernetes.executor.container.image": "eragani/spark:3.3.1"
#       "spark.eventLog.enabled": "false"
#       "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#     arguments:
#       - "au03_sales_test"

---

# apiVersion: argoproj.io/v1alpha1
# kind: CronWorkflow
# metadata:
#   name: user-cdc-event-proc-1
#   namespace: au05-sales-test
# spec:
#   schedule: "*/2 * * * *"
#   concurrencyPolicy: Forbid
#   startingDeadlineSeconds: 0
#   workflowSpec:
#     entrypoint: submit-spark-job-1
#     synchronization:  # Defining the synchronization policy here
#       mutex:
#         name: my-mutex
#     priorityClassName: high-priority
#     serviceAccountName: spark
#     templates:
#       - name: submit-spark-job-1
#         resource:
#           action: create
#           manifest: |
#             apiVersion: sparkoperator.k8s.io/v1beta2
#             kind: SparkApplication
#             metadata:
#               generateName: user-cdc-event-proc-
#               namespace: au05-sales-test
#             spec:
#               type: Scala
#               mode: cluster
#               image: "eragani/spark:3.3.1"
#               mainClass: "step1.UserCDCEventProcessor"
#               mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#               sparkVersion: "3.3.1"
#               restartPolicy:
#                 type: Never
#               driver:
#                 cores: 1
#                 coreLimit: "1"
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#                 serviceAccount: spark
#               executor:
#                 cores: 1
#                 instances: 1
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#               sparkConf:
#                 "spark.kubernetes.namespace": "au05-sales-test"
#                 "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#                 "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#                 "spark.eventLog.enabled": "false"
#                 "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#               arguments:
#                 - "au03_sales_test"
# ---
# apiVersion: argoproj.io/v1alpha1
# kind: CronWorkflow
# metadata:
#   name: user-cdc-event-proc-2
#   namespace: au05-sales-test
# spec:
#   schedule: "*/4 * * * *"
#   concurrencyPolicy: Forbid
#   startingDeadlineSeconds: 0
#   workflowSpec:
#     entrypoint: submit-spark-job-2
#     synchronization:  # Defining the synchronization policy here
#       mutex:
#         name: my-mutex
#     priorityClassName: low-priority
#     serviceAccountName: spark
#     templates:
#       - name: submit-spark-job-2
#         resource:
#           action: create
#           manifest: |
#             apiVersion: sparkoperator.k8s.io/v1beta2
#             kind: SparkApplication
#             metadata:
#               generateName: user-cdc-event-proc-
#               namespace: au05-sales-test
#             spec:
#               type: Scala
#               mode: cluster
#               image: "eragani/spark:3.3.1"
#               mainClass: "step1.UserCDCEventProcessor"
#               mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#               sparkVersion: "3.3.1"
#               restartPolicy:
#                 type: Never
#               driver:
#                 cores: 1
#                 coreLimit: "1"
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#                 serviceAccount: spark
#               executor:
#                 cores: 1
#                 instances: 1
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#               sparkConf:
#                 "spark.kubernetes.namespace": "au05-sales-test"
#                 "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#                 "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#                 "spark.eventLog.enabled": "false"
#                 "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#               arguments:
#                 - "au03_sales_test"
---
# apiVersion: argoproj.io/v1alpha1
# kind: CronWorkflow
# metadata:
#   name: user-cdc-event-proc-1
#   namespace: au05-sales-test
# spec:
#   schedule: "*/2 * * * *"
#   concurrencyPolicy: Forbid
#   startingDeadlineSeconds: 0
#   workflowSpec:
#     entrypoint: submit-spark-job-1
#     synchronization:
#       mutex:
#         name: my-mutex
#     priorityClassName: high-priority
#     serviceAccountName: spark
#     templates:
#       - name: submit-spark-job-1
#         resource:
#           action: create
#           manifest: |
#             apiVersion: sparkoperator.k8s.io/v1beta2
#             kind: SparkApplication
#             metadata:
#               generateName: user-cdc-event-proc-
#               namespace: au05-sales-test
#             spec:
#               type: Scala
#               mode: cluster
#               image: "eragani/spark:3.3.1"
#               mainClass: "step1.UserCDCEventProcessor"
#               mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#               sparkVersion: "3.3.1"
#               restartPolicy:
#                 type: Never
#               driver:
#                 cores: 1
#                 coreLimit: "1"
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#                 serviceAccount: spark
#               executor:
#                 cores: 1
#                 instances: 1
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#               sparkConf:
#                 "spark.kubernetes.namespace": "au05-sales-test"
#                 "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#                 "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#                 "spark.eventLog.enabled": "false"
#                 "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#               arguments:
#                 - "au03_sales_test"
 
#       - name: wait-for-spark-job-1
#         dependencies: [submit-spark-job-1]
#         container:
#           image: busybox:latest
#           command: ["sh", "-c", "while [ $(kubectl get sparkapplications.sparkoperator.k8s.io -n au05-sales-test | grep user-cdc-event-proc- | wc -l) -gt 0 ]; do sleep 10; done"]
 
---
# apiVersion: argoproj.io/v1alpha1
# kind: CronWorkflow
# metadata:
#   name: user-cdc-event-proc-2
#   namespace: au05-sales-test
# spec:
#   schedule: "*/4 * * * *"
#   concurrencyPolicy: Forbid
#   startingDeadlineSeconds: 0
#   workflowSpec:
#     entrypoint: submit-spark-job-2
#     synchronization:
#       mutex:
#         name: my-mutex
#     priorityClassName: low-priority
#     serviceAccountName: spark
#     templates:
#       - name: submit-spark-job-2
#         resource:
#           action: create
#           manifest: |
#             apiVersion: sparkoperator.k8s.io/v1beta2
#             kind: SparkApplication
#             metadata:
#               generateName: user-cdc-event-proc-
#               namespace: au05-sales-test
#             spec:
#               type: Scala
#               mode: cluster
#               image: "eragani/spark:3.3.1"
#               mainClass: "step1.UserCDCEventProcessor"
#               mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
#               sparkVersion: "3.3.1"
#               restartPolicy:
#                 type: Never
#               driver:
#                 cores: 1
#                 coreLimit: "1"
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#                 serviceAccount: spark
#               executor:
#                 cores: 1
#                 instances: 1
#                 memory: "512m"
#                 memoryOverhead: "512m"
#                 labels:
#                   version: 3.3.1
#               sparkConf:
#                 "spark.kubernetes.namespace": "au05-sales-test"
#                 "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
#                 "spark.kubernetes.container.image": "eragani/spark:3.3.1"
#                 "spark.eventLog.enabled": "false"
#                 "spark.kubernetes.container.image.pullSecrets": "docker-secret"
#               arguments:
#                 - "au03_sales_test"
 
#       - name: wait-for-spark-job-2
#         dependencies: [submit-spark-job-2]
#         container:
#           image: busybox:latest
#           command: ["sh", "-c", "while [ $(kubectl get sparkapplications.sparkoperator.k8s.io -n au05-sales-test | grep user-cdc-event-proc- | wc -l) -gt 0 ]; do sleep 10; done"]
---
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: user-cdc-event-proc-1
  namespace: au05-sales-test
spec:
  schedule: "*/2 * * * *"
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 0
  workflowSpec:
    entrypoint: submit-and-wait-spark-job
    synchronization:
      mutex:
        name: my-mutex
    priorityClassName: high-priority
    serviceAccountName: spark
    templates:
      - name: submit-and-wait-spark-job
        steps:
          - - name: submit-spark-job
              template: submit-spark-job-1
          - - name: wait-for-spark-job
              template: wait-for-spark-job-1
              arguments:
                parameters:
                  - name: spark-application-name
                    value: "{{steps.submit-spark-job.outputs.parameters.spark-application-name}}"

      - name: submit-spark-job-1
        resource:
          action: create
          manifest: |
            apiVersion: sparkoperator.k8s.io/v1beta2
            kind: SparkApplication
            metadata:
              generateName: user-cdc-event-proc-
              namespace: au05-sales-test
            spec:
              type: Scala
              mode: cluster
              image: "eragani/spark:3.3.1"
              mainClass: "step1.UserCDCEventProcessor"
              mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
              sparkVersion: "3.3.1"
              restartPolicy:
                type: Never
              driver:
                cores: 1
                coreLimit: "1"
                memory: "512m"
                memoryOverhead: "512m"
                labels:
                  version: 3.3.1
                serviceAccount: spark
              executor:
                cores: 1
                instances: 1
                memory: "512m"
                memoryOverhead: "512m"
                labels:
                  version: 3.3.1
              sparkConf:
                "spark.kubernetes.namespace": "au05-sales-test"
                "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
                "spark.kubernetes.container.image": "eragani/spark:3.3.1"
                "spark.eventLog.enabled": "false"
                "spark.kubernetes.container.image.pullSecrets": "docker-secret"
              arguments:
                - "au03_sales_test"
        outputs:
          parameters:
            - name: spark-application-name
              valueFrom:
                jsonPath: '{.metadata.name}'

      - name: wait-for-spark-job-1
        inputs:
          parameters:
            - name: spark-application-name
        script:
          image: portainer/kubectl-shell:latest  #bitnami/kubectl:latest
          # workingDir: "/tmp"  # Set a writable working directory
          command: [sh]
          source: |
            APP_NAME="{{inputs.parameters.spark-application-name}}"
            RUNNING="true"
            echo "Checking status of SparkApplication: $APP_NAME"
            while [ "$RUNNING" = "true" ]; do
              STATE=$(kubectl get sparkapplications "$APP_NAME" -n au05-sales-test -o jsonpath='{.status.applicationState.state}')
              echo "Current State: $STATE"
              if [ "$STATE" = "COMPLETED" ]; then
                echo "SparkApplication completed."
                RUNNING="false"
              elif [ "$STATE" = "FAILED" ]; then
                echo "SparkApplication failed."
                RUNNING="false"
              else
                sleep 10  # Wait before checking the status again
              fi
            done
            # When the loop exits, we assume the job is done, so we sleep briefly before exiting the script
            sleep 5
            echo "Exiting the shell now."
            exit 0
          securityContext:
            runAsUser: 0
---
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: user-cdc-event-proc-2
  namespace: au05-sales-test
spec:
  schedule: "*/4 * * * *"
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 0
  workflowSpec:
    entrypoint: submit-and-wait-spark-job-2
    synchronization:
      mutex:
        name: my-mutex
    priorityClassName: low-priority
    serviceAccountName: spark
    templates:
      - name: submit-and-wait-spark-job-2
        steps:
          - - name: submit-spark-job
              template: submit-spark-job-2
          - - name: wait-for-spark-job
              template: wait-for-spark-job-2
              arguments:
                parameters:
                  - name: spark-application-name
                    value: "{{steps.submit-spark-job.outputs.parameters.spark-application-name}}"

      - name: submit-spark-job-2
        resource:
          action: create
          manifest: |
            apiVersion: sparkoperator.k8s.io/v1beta2
            kind: SparkApplication
            metadata:
              generateName: user-cdc-event-proc-
              namespace: au05-sales-test
            spec:
              type: Scala
              mode: cluster
              image: "eragani/spark:3.3.1"
              mainClass: "step1.UserCDCEventProcessor"
              mainApplicationFile: "local:///opt/suite/audience2.0/Audience-assembly-0.1.0.jar"
              sparkVersion: "3.3.1"
              restartPolicy:
                type: Never
              driver:
                cores: 1
                coreLimit: "1"
                memory: "512m"
                memoryOverhead: "512m"
                labels:
                  version: 3.3.1
                serviceAccount: spark
              executor:
                cores: 1
                instances: 1
                memory: "512m"
                memoryOverhead: "512m"
                labels:
                  version: 3.3.1
              sparkConf:
                "spark.kubernetes.namespace": "au05-sales-test"
                "spark.kubernetes.authenticate.driver.serviceAccountName": "spark"
                "spark.kubernetes.container.image": "eragani/spark:3.3.1"
                "spark.eventLog.enabled": "false"
                "spark.kubernetes.container.image.pullSecrets": "docker-secret"
              arguments:
                - "au03_sales_test"
        outputs:
          parameters:
            - name: spark-application-name
              valueFrom:
                jsonPath: '{.metadata.name}'

      - name: wait-for-spark-job-2
        inputs:
          parameters:
            - name: spark-application-name
        script:
          image: portainer/kubectl-shell:latest  #bitnami/kubectl:latest
          # workingDir: "/tmp"  # Set a writable working directory
          command: [sh]
          source: |
            APP_NAME="{{inputs.parameters.spark-application-name}}"
            RUNNING="true"
            echo "Checking status of SparkApplication: $APP_NAME"
            while [ "$RUNNING" = "true" ]; do
              STATE=$(kubectl get sparkapplications "$APP_NAME" -n au05-sales-test -o jsonpath='{.status.applicationState.state}')
              echo "Current State: $STATE"
              if [ "$STATE" = "COMPLETED" ]; then
                echo "SparkApplication completed."
                RUNNING="false"
              elif [ "$STATE" = "FAILED" ]; then
                echo "SparkApplication failed."
                RUNNING="false"
              else
                sleep 10  # Wait before checking the status again
              fi
            done
            # When the loop exits, we assume the job is done, so we sleep briefly before exiting the script
            sleep 5
            echo "Exiting the shell now."
            exit 0
          securityContext:
            runAsUser: 0
